{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8617572,"sourceType":"datasetVersion","datasetId":5153861}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(done)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom glob import glob\n\n# Paths to your dataset\ndataset_path = \"/kaggle/input/arabic-egy-asr-16k/train\"\ncsv_file_path = \"/kaggle/input/arabic-egy-asr-16k/train.csv\"\n\n# Read the .csv file\ndata = pd.read_csv(csv_file_path)\n\n# Dictionary to map audio IDs to transcripts\nid_to_text = dict(zip(data['audio'], data['transcript']))\n\n# Find all .wav files in the dataset path\nwavs = glob(f\"{dataset_path}/*.wav\")\n\n# Print the first few entries to verify\nprint(wavs[:5])\nprint(list(id_to_text.items())[:5])","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:06:14.533273Z","iopub.execute_input":"2024-06-21T17:06:14.533522Z","iopub.status.idle":"2024-06-21T17:06:16.660479Z","shell.execute_reply.started":"2024-06-21T17:06:14.533501Z","shell.execute_reply":"2024-06-21T17:06:16.659507Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"['/kaggle/input/arabic-egy-asr-16k/train/train_sample_29416.wav', '/kaggle/input/arabic-egy-asr-16k/train/train_sample_24087.wav', '/kaggle/input/arabic-egy-asr-16k/train/train_sample_32680.wav', '/kaggle/input/arabic-egy-asr-16k/train/train_sample_1415.wav', '/kaggle/input/arabic-egy-asr-16k/train/train_sample_20050.wav']\n[('train_sample_0', 'على إنها عار في الوقت اللي كانت بتتعامل مع أخويا الولد الوحيد معامله خاصه'), ('train_sample_1', 'فأكيد ربنا عوضهم خير هو الراجل بيبقى ليه إختيارات معينه إم وشايف إن دول الأنسب لمنتخب مصر في الفتره'), ('train_sample_2', 'زي دول كتيره بنشوفها النهارده في العالم وأصبحت هذه الدول أمثله للنجاح والتق'), ('train_sample_3', 'يعني مين اللي بيحط شروطها يعني أنا شايفه إني متوافقه مع كذا'), ('train_sample_4', 'والله هي الموضوع مش كليب خلي بالك ولا أغنيه الموضوع هو مشروع مشروع أنا قولت أعمله يعني اللي أنا أقدر عليه')]\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_data(wavs, id_to_text, maxlen=50):\n    \"\"\"Returns mapping of audio paths and transcription texts\"\"\"\n    data = []\n    for w in wavs:\n        # Extract the ID from the file name\n        id = os.path.basename(w).split(\".\")[0]\n        text = id_to_text.get(id)\n        # Check if text is valid and meets length requirements\n        if isinstance(text, str) and len(text) < maxlen:\n            data.append({\"audio\": w, \"text\": text})\n    return data\n\n# Example usage\ndata = get_data(wavs, id_to_text, maxlen=247)\n\n# Print the first few entries to verify\nprint(data[:5])","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:06:16.662042Z","iopub.execute_input":"2024-06-21T17:06:16.662322Z","iopub.status.idle":"2024-06-21T17:06:16.811331Z","shell.execute_reply.started":"2024-06-21T17:06:16.662297Z","shell.execute_reply":"2024-06-21T17:06:16.810397Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[{'audio': '/kaggle/input/arabic-egy-asr-16k/train/train_sample_29416.wav', 'text': 'مصر بتقف جنبه على مر العصور وعلى مر التاريخ علمت صحيح الوطن العربي كله وتاريخك'}, {'audio': '/kaggle/input/arabic-egy-asr-16k/train/train_sample_24087.wav', 'text': 'فقالولي تمام بس إحنا عايزينك تيجي هونج كونج تعيش في هونج كونج تشتغل هناك'}, {'audio': '/kaggle/input/arabic-egy-asr-16k/train/train_sample_32680.wav', 'text': 'كزبرة أوكي والتوم لمون وكزبره وتوم وتوم'}, {'audio': '/kaggle/input/arabic-egy-asr-16k/train/train_sample_1415.wav', 'text': 'بس مخدش حقه أوي لأن هو قعد حوالي سبع تمن سنين في الجيش و بعد كده اما طلع'}, {'audio': '/kaggle/input/arabic-egy-asr-16k/train/train_sample_20050.wav', 'text': 'ليه على ما المشهد يوضح قدامي على ما الصوره تكتمل'}]\n","output_type":"stream"}]},{"cell_type":"code","source":"class VectorizeChar:\n    def __init__(self, max_len=50):\n        # Define Arabic character set and common symbols\n        self.vocab = (\n            [\"-\", \"#\", \"<\", \">\"]\n            + [chr(i) for i in range(1569, 1611)]  # Arabic characters range\n            + [\" \", \".\", \",\", \"؟\", \"ـ\"]\n        )\n        self.max_len = max_len\n        self.char_to_idx = {}\n        for i, ch in enumerate(self.vocab):\n            self.char_to_idx[ch] = i\n\n    def __call__(self, text):\n        text = text[: self.max_len - 2]\n        text = \"<\" + text + \">\"\n        pad_len = self.max_len - len(text)\n        return [self.char_to_idx.get(ch, 1) for ch in text] + [0] * pad_len\n\n    def get_vocabulary(self):\n        return self.vocab\n\n# Initialize vectorizer\nvectorizer = VectorizeChar(max_len=50)\n\n# Example usage\ntext = \"بلال شامة\"\nvectorized_text = vectorizer(text)\nprint(vectorized_text)\n\n# Get vocabulary\nvocab = vectorizer.get_vocabulary()\nprint(vocab)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:06:16.812404Z","iopub.execute_input":"2024-06-21T17:06:16.812690Z","iopub.status.idle":"2024-06-21T17:06:16.823294Z","shell.execute_reply.started":"2024-06-21T17:06:16.812665Z","shell.execute_reply":"2024-06-21T17:06:16.821984Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[2, 11, 39, 10, 39, 46, 23, 10, 40, 12, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n['-', '#', '<', '>', 'ء', 'آ', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ػ', 'ؼ', 'ؽ', 'ؾ', 'ؿ', 'ـ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي', ' ', '.', ',', '؟', 'ـ']\n","output_type":"stream"}]},{"cell_type":"code","source":"max_target_len = 247\ndata = get_data(wavs, id_to_text, max_target_len)\nvectorizer = VectorizeChar(max_target_len)\nprint(\"vocab size\", len(vectorizer.get_vocabulary()))","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:06:32.612143Z","iopub.execute_input":"2024-06-21T17:06:32.613020Z","iopub.status.idle":"2024-06-21T17:06:32.776454Z","shell.execute_reply.started":"2024-06-21T17:06:32.612987Z","shell.execute_reply":"2024-06-21T17:06:32.775247Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"vocab size 51\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n\ndef create_text_ds(data, vectorizer):\n    texts = [_[\"text\"] for _ in data]\n    text_ds = [vectorizer(t) for t in texts]\n    text_ds = tf.data.Dataset.from_tensor_slices(text_ds)\n    return text_ds\n\ntext_ds = create_text_ds(data, vectorizer)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:06:38.311911Z","iopub.execute_input":"2024-06-21T17:06:38.312275Z","iopub.status.idle":"2024-06-21T17:07:27.431012Z","shell.execute_reply.started":"2024-06-21T17:06:38.312245Z","shell.execute_reply":"2024-06-21T17:07:27.429986Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"2024-06-21 17:06:39.885567: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-21 17:06:39.885661: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-21 17:06:39.999886: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Function to calculate spectrogram length for a single audio file\ndef calculate_spectrogram_length(audio_path):\n    audio = tf.io.read_file(audio_path)\n    audio, _ = tf.audio.decode_wav(audio, 1)\n    audio = tf.squeeze(audio, axis=-1)\n    stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256)\n    spectrogram = tf.math.pow(tf.abs(stfts), 0.5)\n    return tf.shape(spectrogram)[0]\n\n# Function to iterate over folder and calculate max_pad_len\ndef calculate_max_pad_len(folder_path):\n    max_length = 0\n    wav_files = glob(os.path.join(folder_path, '*.wav'))\n    for path in wav_files:\n        length = calculate_spectrogram_length(path)\n        if length > max_length:\n            max_length = length\n    return max_length\n\n# Example folder path containing all .wav files\nfolder_path = '/kaggle/input/arabic-egy-asr-16k/train'\n\n# Calculate max_pad_len\nmax_pad_len = calculate_max_pad_len(folder_path)\nprint(\"Max Pad Length:\", max_pad_len)\n\n# Optional: Plot length distribution\ndef plot_length_distribution(folder_path):\n    wav_files = glob(os.path.join(folder_path, '*.wav'))\n    lengths = [calculate_spectrogram_length(path) for path in wav_files]\n    plt.hist(lengths, bins=30)\n    plt.xlabel('Spectrogram Length')\n    plt.ylabel('Count')\n    plt.title('Distribution of Spectrogram Lengths')\n    plt.show()\n\n# Example usage to plot length distribution\nplot_length_distribution(folder_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T04:58:40.521283Z","iopub.execute_input":"2024-06-21T04:58:40.522378Z","iopub.status.idle":"2024-06-21T05:23:47.792385Z","shell.execute_reply.started":"2024-06-21T04:58:40.522336Z","shell.execute_reply":"2024-06-21T05:23:47.791387Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Max Pad Length: tf.Tensor(2558, shape=(), dtype=int32)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"def path_to_audio(path, max_pad_len=2558):\n    # Read and decode audio file\n    audio = tf.io.read_file(path)\n    audio, _ = tf.audio.decode_wav(audio, 1)\n    audio = tf.squeeze(audio, axis=-1)\n    \n    # Compute STFT\n    stfts = tf.signal.stft(audio, frame_length=200, frame_step=80, fft_length=256)\n    x = tf.math.pow(tf.abs(stfts), 0.5)\n    \n    # Normalization\n    means = tf.math.reduce_mean(x, 1, keepdims=True)\n    stddevs = tf.math.reduce_std(x, 1, keepdims=True)\n    x = (x - means) / (stddevs + 1e-6)  # Adding a small epsilon to avoid division by zero\n    \n    # Padding to max_pad_len frames\n    audio_len = tf.shape(x)[0]\n    pad_len = tf.maximum(max_pad_len - audio_len, 0)  # Ensure pad_len is non-negative\n    paddings = tf.convert_to_tensor([[0, pad_len], [0, 0]], dtype=tf.int32)  # Convert to tensor with consistent dtype\n    x = tf.pad(x, paddings, \"CONSTANT\")[:max_pad_len, :]\n    \n    return x\n\n# Example usage\naudio_path = \"/kaggle/input/arabic-egy-asr-16k/train/train_sample_0.wav\"\nspectrogram = path_to_audio(audio_path)\nprint(\"Spectrogram shape:\", spectrogram.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:07:27.432919Z","iopub.execute_input":"2024-06-21T17:07:27.433492Z","iopub.status.idle":"2024-06-21T17:07:28.911326Z","shell.execute_reply.started":"2024-06-21T17:07:27.433457Z","shell.execute_reply":"2024-06-21T17:07:28.910359Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Spectrogram shape: (2558, 129)\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_audio_ds(data):\n    flist = [_[\"audio\"] for _ in data]  # Extract audio file paths from data\n    audio_ds = tf.data.Dataset.from_tensor_slices(flist)  # Create dataset from paths\n    audio_ds = audio_ds.map(path_to_audio, num_parallel_calls=tf.data.AUTOTUNE)  # Apply path_to_audio function\n    return audio_ds\n\n# Create audio dataset\naudio_ds = create_audio_ds(data)\n\nfor spectrogram in audio_ds.take(1):\n    print(\"Spectrogram shape:\", spectrogram.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:07:28.912410Z","iopub.execute_input":"2024-06-21T17:07:28.912700Z","iopub.status.idle":"2024-06-21T17:07:29.423959Z","shell.execute_reply.started":"2024-06-21T17:07:28.912675Z","shell.execute_reply":"2024-06-21T17:07:29.422906Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Spectrogram shape: (2558, 129)\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_tf_dataset(data, vectorizer, bs=4):\n    # Step 1: Create audio dataset\n    audio_ds = create_audio_ds(data)\n    \n    # Step 2: Create text dataset using the provided vectorizer\n    text_ds = create_text_ds(data, vectorizer)\n    \n    # Step 3: Zip audio and text datasets together\n    ds = tf.data.Dataset.zip((audio_ds, text_ds))\n    \n    # Step 4: Map to create final dataset format\n    ds = ds.map(lambda x, y: {\"source\": x, \"target\": y})\n    \n    # Step 5: Batch the dataset\n    ds = ds.batch(bs)\n    \n    # Step 6: Prefetch data for performance optimization\n    ds = ds.prefetch(tf.data.AUTOTUNE)\n    \n    return ds\n\n# Create vectorizer\nvectorizer = VectorizeChar(max_len=51)\n\n# Create TensorFlow dataset\ndataset = create_tf_dataset(data, vectorizer, bs=4)\n\n# Iterate over batches in the dataset\nfor batch in dataset.take(1):\n    sources, targets = batch[\"source\"], batch[\"target\"]\n    print(\"Sources batch shape:\", sources.shape)\n    print(\"Targets batch shape:\", targets.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:07:29.426285Z","iopub.execute_input":"2024-06-21T17:07:29.426587Z","iopub.status.idle":"2024-06-21T17:07:38.236014Z","shell.execute_reply.started":"2024-06-21T17:07:29.426560Z","shell.execute_reply":"2024-06-21T17:07:38.234971Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Sources batch shape: (4, 2558, 129)\nTargets batch shape: (4, 51)\n","output_type":"stream"}]},{"cell_type":"code","source":"split = int(len(data) * 0.99)\ntrain_data = data[:split]\ndev_data = data[split:]\n\n# Create training dataset\ntrain_ds = create_tf_dataset(train_data, vectorizer, bs=64)\n\n# Create validation dataset\ndev_ds = create_tf_dataset(dev_data, vectorizer, bs=4)\n\n# Print dataset shapes\nprint(\"Training Dataset Shapes:\")\nfor batch in train_ds.take(1):\n    sources, targets = batch[\"source\"], batch[\"target\"]\n    print(\"Sources batch shape:\", sources.shape)\n    print(\"Targets batch shape:\", targets.shape)\n\nprint(\"\\nValidation Dataset Shapes:\")\nfor batch in dev_ds.take(1):\n    sources, targets = batch[\"source\"], batch[\"target\"]\n    print(\"Sources batch shape:\", sources.shape)\n    print(\"Targets batch shape:\", targets.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:07:38.237704Z","iopub.execute_input":"2024-06-21T17:07:38.238098Z","iopub.status.idle":"2024-06-21T17:07:47.252065Z","shell.execute_reply.started":"2024-06-21T17:07:38.238064Z","shell.execute_reply":"2024-06-21T17:07:47.251083Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Training Dataset Shapes:\nSources batch shape: (64, 2558, 129)\nTargets batch shape: (64, 51)\n\nValidation Dataset Shapes:\nSources batch shape: (4, 2558, 129)\nTargets batch shape: (4, 51)\n","output_type":"stream"}]},{"cell_type":"code","source":"import keras\nfrom keras import layers\n\nclass TextEmbedding(layers.Layer):\n    def __init__(self, num_vocab=1000, maxlen=100, num_hid=64):\n        super().__init__()\n        self.emb = keras.layers.Embedding(num_vocab, num_hid)\n        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=num_hid)\n\n    def call(self, x):\n        maxlen = tf.shape(x)[-1]\n        x = self.emb(x)\n        positions = tf.range(start=0, limit=maxlen, delta=1)\n        positions = self.pos_emb(positions)\n        return x + positions","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:07:47.253760Z","iopub.execute_input":"2024-06-21T17:07:47.254134Z","iopub.status.idle":"2024-06-21T17:07:47.260772Z","shell.execute_reply.started":"2024-06-21T17:07:47.254102Z","shell.execute_reply":"2024-06-21T17:07:47.259851Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class AudioFeatureExtraction(layers.Layer):\n    def __init__(self, num_hid=64, maxlen=100):\n        super().__init__()\n        self.conv1 = keras.layers.Conv1D(\n            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n        )\n        self.conv2 = keras.layers.Conv1D(\n            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n        )\n        self.conv3 = keras.layers.Conv1D(\n            num_hid, 11, strides=2, padding=\"same\", activation=\"relu\"\n        )\n\n    def call(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        return self.conv3(x)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:07:47.262089Z","iopub.execute_input":"2024-06-21T17:07:47.262430Z","iopub.status.idle":"2024-06-21T17:07:47.277543Z","shell.execute_reply.started":"2024-06-21T17:07:47.262401Z","shell.execute_reply":"2024-06-21T17:07:47.276596Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Encoder(layers.Layer):\n    def __init__(self, embed_dim, num_heads, feed_forward_dim, rate=0.1):\n        super().__init__()\n        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.ffn = keras.Sequential(\n            [\n                layers.Dense(feed_forward_dim, activation=\"relu\"),\n                layers.Dense(embed_dim),\n            ]\n        )\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.dropout1 = layers.Dropout(rate)\n        self.dropout2 = layers.Dropout(rate)\n\n    def call(self, inputs, training=False):\n        attn_output = self.att(inputs, inputs)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(inputs + attn_output)\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:07:47.278488Z","iopub.execute_input":"2024-06-21T17:07:47.278726Z","iopub.status.idle":"2024-06-21T17:07:47.287744Z","shell.execute_reply.started":"2024-06-21T17:07:47.278705Z","shell.execute_reply":"2024-06-21T17:07:47.286983Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class Decoder(layers.Layer):\n    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout_rate=0.1):\n        super().__init__()\n        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n        self.layernorm3 = layers.LayerNormalization(epsilon=1e-6)\n        self.self_att = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.enc_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n        self.self_dropout = layers.Dropout(0.5)\n        self.enc_dropout = layers.Dropout(0.1)\n        self.ffn_dropout = layers.Dropout(0.1)\n        self.ffn = keras.Sequential(\n            [\n                layers.Dense(feed_forward_dim, activation=\"relu\"),\n                layers.Dense(embed_dim),\n            ]\n        )\n\n    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n        i = tf.range(n_dest)[:, None]\n        j = tf.range(n_src)\n        m = i >= j - n_src + n_dest\n        mask = tf.cast(m, dtype)\n        mask = tf.reshape(mask, [1, n_dest, n_src])\n        mult = tf.concat(\n            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n        )\n        return tf.tile(mask, mult)\n\n    def call(self, enc_out, target):\n        input_shape = tf.shape(target)\n        batch_size = input_shape[0]\n        seq_len = input_shape[1]\n        causal_mask = self.causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n        target_att = self.self_att(target, target, attention_mask=causal_mask)\n        target_norm = self.layernorm1(target + self.self_dropout(target_att))\n        enc_out = self.enc_att(target_norm, enc_out)\n        enc_out_norm = self.layernorm2(self.enc_dropout(enc_out) + target_norm)\n        ffn_out = self.ffn(enc_out_norm)\n        ffn_out_norm = self.layernorm3(enc_out_norm + self.ffn_dropout(ffn_out))\n        return ffn_out_norm","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:07:47.288827Z","iopub.execute_input":"2024-06-21T17:07:47.289135Z","iopub.status.idle":"2024-06-21T17:07:47.302145Z","shell.execute_reply.started":"2024-06-21T17:07:47.289112Z","shell.execute_reply":"2024-06-21T17:07:47.301373Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class Transformer(keras.Model):\n    def __init__(\n        self,\n        num_hid=64,\n        num_head=2,\n        num_feed_forward=128,\n        source_maxlen=100,\n        target_maxlen=100,\n        num_layers_enc=4,\n        num_layers_dec=1,\n        num_classes=10,\n    ):\n        super().__init__()\n        self.loss_metric = keras.metrics.Mean(name=\"loss\")\n        self.num_layers_enc = num_layers_enc\n        self.num_layers_dec = num_layers_dec\n        self.target_maxlen = target_maxlen\n        self.num_classes = num_classes\n\n        self.enc_input = AudioFeatureExtraction(num_hid=num_hid, maxlen=source_maxlen)\n        self.dec_input = TextEmbedding(\n            num_vocab=num_classes, maxlen=target_maxlen, num_hid=num_hid\n        )\n\n        self.encoder = keras.Sequential(\n            [self.enc_input]\n            + [\n                Encoder(num_hid, num_head, num_feed_forward)\n                for _ in range(num_layers_enc)\n            ]\n        )\n\n        for i in range(num_layers_dec):\n            setattr(\n                self,\n                f\"dec_layer_{i}\",\n                Decoder(num_hid, num_head, num_feed_forward),\n            )\n\n        self.classifier = layers.Dense(num_classes)\n\n    def decode(self, enc_out, target):\n        y = self.dec_input(target)\n        for i in range(self.num_layers_dec):\n            y = getattr(self, f\"dec_layer_{i}\")(enc_out, y)\n        return y\n\n    def call(self, inputs):\n        source = inputs[0]\n        target = inputs[1]\n        x = self.encoder(source)\n        y = self.decode(x, target)\n        return self.classifier(y)\n\n    @property\n    def metrics(self):\n        return [self.loss_metric]\n\n    def train_step(self, batch):\n        source = batch[\"source\"]\n        target = batch[\"target\"]\n        dec_input = target[:, :-1]\n        dec_target = target[:, 1:]\n        with tf.GradientTape() as tape:\n            preds = self([source, dec_input])\n            one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n            mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n            loss = model.compute_loss(None, one_hot, preds, sample_weight=mask)\n        trainable_vars = self.trainable_variables\n        gradients = tape.gradient(loss, trainable_vars)\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n        self.loss_metric.update_state(loss)\n        return {\"loss\": self.loss_metric.result()}\n\n    def test_step(self, batch):\n        source = batch[\"source\"]\n        target = batch[\"target\"]\n        dec_input = target[:, :-1]\n        dec_target = target[:, 1:]\n        preds = self([source, dec_input])\n        one_hot = tf.one_hot(dec_target, depth=self.num_classes)\n        mask = tf.math.logical_not(tf.math.equal(dec_target, 0))\n        loss = model.compute_loss(None, one_hot, preds, sample_weight=mask)\n        self.loss_metric.update_state(loss)\n        return {\"loss\": self.loss_metric.result()}\n\n    def generate(self, source, target_start_token_idx):\n        bs = tf.shape(source)[0]\n        enc = self.encoder(source)\n        dec_input = tf.ones((bs, 1), dtype=tf.int32) * target_start_token_idx\n        dec_logits = []\n        for i in range(self.target_maxlen - 1):\n            dec_out = self.decode(enc, dec_input)\n            logits = self.classifier(dec_out)\n            logits = tf.argmax(logits, axis=-1, output_type=tf.int32)\n            last_logit = tf.expand_dims(logits[:, -1], axis=-1)\n            dec_logits.append(last_logit)\n            dec_input = tf.concat([dec_input, last_logit], axis=-1)\n        return dec_input","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:07:47.304797Z","iopub.execute_input":"2024-06-21T17:07:47.305516Z","iopub.status.idle":"2024-06-21T17:07:47.325554Z","shell.execute_reply.started":"2024-06-21T17:07:47.305489Z","shell.execute_reply":"2024-06-21T17:07:47.324751Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class DisplayOutputs(keras.callbacks.Callback):\n    def __init__(\n        self, batch, idx_to_token, target_start_token_idx=27, target_end_token_idx=28\n    ):\n        self.batch = batch\n        self.target_start_token_idx = target_start_token_idx\n        self.target_end_token_idx = target_end_token_idx\n        self.idx_to_char = idx_to_token\n\n    def on_epoch_end(self, epoch, logs=None):\n        if epoch % 5 != 0:\n            return\n        source = self.batch[\"source\"]\n        target = self.batch[\"target\"].numpy()\n        bs = tf.shape(source)[0]\n        preds = self.model.generate(source, self.target_start_token_idx)\n        preds = preds.numpy()\n        for i in range(bs):\n            target_text = \"\".join([self.idx_to_char[_] for _ in target[i, :]])\n            prediction = \"\"\n            for idx in preds[i, :]:\n                prediction += self.idx_to_char[idx]\n                if idx == self.target_end_token_idx:\n                    break\n            print(f\"target:     {target_text.replace('-','')}\")\n            print(f\"prediction: {prediction}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:07:47.326415Z","iopub.execute_input":"2024-06-21T17:07:47.326727Z","iopub.status.idle":"2024-06-21T17:07:47.337629Z","shell.execute_reply.started":"2024-06-21T17:07:47.326704Z","shell.execute_reply":"2024-06-21T17:07:47.336771Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class CustomSchedule(keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(\n        self,\n        init_lr=0.00001,\n        lr_after_warmup=0.001,\n        final_lr=0.00001,\n        warmup_epochs=15,\n        decay_epochs=85,\n        steps_per_epoch=203,\n    ):\n        super().__init__()\n        self.init_lr = init_lr\n        self.lr_after_warmup = lr_after_warmup\n        self.final_lr = final_lr\n        self.warmup_epochs = warmup_epochs\n        self.decay_epochs = decay_epochs\n        self.steps_per_epoch = steps_per_epoch\n\n    def calculate_lr(self, epoch):\n        \"\"\"linear warm up - linear decay\"\"\"\n        warmup_lr = (\n            self.init_lr\n            + ((self.lr_after_warmup - self.init_lr) / (self.warmup_epochs - 1)) * epoch\n        )\n        decay_lr = tf.math.maximum(\n            self.final_lr,\n            self.lr_after_warmup\n            - (epoch - self.warmup_epochs)\n            * (self.lr_after_warmup - self.final_lr)\n            / self.decay_epochs,\n        )\n        return tf.math.minimum(warmup_lr, decay_lr)\n\n    def __call__(self, step):\n        epoch = step // self.steps_per_epoch\n        epoch = tf.cast(epoch, \"float32\")\n        return self.calculate_lr(epoch)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T17:07:47.338634Z","iopub.execute_input":"2024-06-21T17:07:47.338881Z","iopub.status.idle":"2024-06-21T17:07:47.349582Z","shell.execute_reply.started":"2024-06-21T17:07:47.338860Z","shell.execute_reply":"2024-06-21T17:07:47.348719Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"batch = next(iter(dev_ds))\n\nidx_to_char = vectorizer.get_vocabulary()\ndisplay_cb = DisplayOutputs(\n    batch, idx_to_char, target_start_token_idx=2, target_end_token_idx=3\n)\n\nkeras.utils.set_random_seed(123)\nmodel = Transformer(\n    num_hid=200,\n    num_head=2,\n    num_feed_forward=400,\n    target_maxlen=247,\n    num_layers_enc=4,\n    num_layers_dec=1,\n    num_classes=51,\n)\nloss_fn = keras.losses.CategoricalCrossentropy(\n    from_logits=True,\n    label_smoothing=0.1,\n)\n\nlearning_rate = CustomSchedule(\n    init_lr=0.00001,\n    lr_after_warmup=0.001,\n    final_lr=0.00001,\n    warmup_epochs=15,\n    decay_epochs=85,\n    steps_per_epoch=len(train_ds),\n)\noptimizer = keras.optimizers.Adam(learning_rate)\nmodel.compile(optimizer=optimizer, loss=loss_fn)\n\nhistory = model.fit(train_ds, validation_data=dev_ds, callbacks=[display_cb], epochs=16)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T16:14:20.486743Z","iopub.execute_input":"2024-06-21T16:14:20.487135Z","iopub.status.idle":"2024-06-21T17:00:18.163140Z","shell.execute_reply.started":"2024-06-21T16:14:20.487107Z","shell.execute_reply":"2024-06-21T17:00:18.162195Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/16\n\u001b[1m  1/785\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:50:43\u001b[0m 36s/step - loss: 4.3555","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1718986496.568694     105 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1718986496.607809     105 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 3.2053","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (4, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"target:     <الحاجه المرعبه وطبعا إحنا كويس إن إنت بتتكلم على >\nprediction: <وال ال ال ال الي ال ال الي المالي الي ال الي الي >\n\ntarget:     <أو المؤسسات ونظام المنظومه الدوليه الأمم المتحده >\nprediction: <وال ال ال ال الي ال ال الي المالي الي ال الي الي >\n\ntarget:     <يعني بتمضي على نفسك شرط جزائي ولا لأ>\nprediction: <وال ال ال ال الي ال ال الي المالي الي ال الي الي >\n\ntarget:     <إنه ما حدث في تونس ليس بعيدا عن هذه القاعه ثم الم>\nprediction: <وال ال ال ال الي ال ال الي المالي الي ال الي الي >\n\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 318ms/step - loss: 3.2049 - val_loss: 2.7405\nEpoch 2/16\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 208ms/step - loss: 2.6805 - val_loss: 2.6219\nEpoch 3/16\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 208ms/step - loss: 2.6120 - val_loss: 2.5476\nEpoch 4/16\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 208ms/step - loss: 2.4704 - val_loss: 2.2682\nEpoch 5/16\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 208ms/step - loss: 2.2226 - val_loss: 2.0830\nEpoch 6/16\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 2.0565target:     <الحاجه المرعبه وطبعا إحنا كويس إن إنت بتتكلم على >\nprediction: <اللي حاجه في أخر من الحاجه في الحاجه في المراج ال>\n\ntarget:     <أو المؤسسات ونظام المنظومه الدوليه الأمم المتحده >\nprediction: <أو ما من المصر المصت في ما ما من المصر من المصر ا>\n\ntarget:     <يعني بتمضي على نفسك شرط جزائي ولا لأ>\nprediction: <مش هتدفاي و أنا مش كان بتدفاي مش كان بتدي>\n\ntarget:     <إنه ما حدث في تونس ليس بعيدا عن هذه القاعه ثم الم>\nprediction: <و المش المخ مستم القاع المش المحد المش المحد الما>\n\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 220ms/step - loss: 2.0565 - val_loss: 1.9512\nEpoch 7/16\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 208ms/step - loss: 1.9289 - val_loss: 1.8673\nEpoch 8/16\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 207ms/step - loss: 1.8330 - val_loss: 1.8102\nEpoch 9/16\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 207ms/step - loss: 1.7676 - val_loss: 1.7806\nEpoch 10/16\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 206ms/step - loss: 1.7194 - val_loss: 1.7485\nEpoch 11/16\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 1.6843target:     <الحاجه المرعبه وطبعا إحنا كويس إن إنت بتتكلم على >\nprediction: <المرارات الجميله بتبقى في أسارات الجميله من الحاج>\n\ntarget:     <أو المؤسسات ونظام المنظومه الدوليه الأمم المتحده >\nprediction: <أول ما والما والمسلست التناح و ما والمعم منظمه و >\n\ntarget:     <يعني بتمضي على نفسك شرط جزائي ولا لأ>\nprediction: <و زي أنا في بتقي و لا أنف ميعي بتقي و لا أنف>\n\ntarget:     <إنه ما حدث في تونس ليس بعيدا عن هذه القاعه ثم الم>\nprediction: <الطاع العنا هداث على المشهد النقال المشهد النشفه >\n\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 216ms/step - loss: 1.6843 - val_loss: 1.7292\nEpoch 12/16\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 208ms/step - loss: 1.6533 - val_loss: 1.7196\nEpoch 13/16\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 208ms/step - loss: 1.6280 - val_loss: 1.7056\nEpoch 14/16\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 208ms/step - loss: 1.6077 - val_loss: 1.6826\nEpoch 15/16\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 209ms/step - loss: 1.5897 - val_loss: 1.6738\nEpoch 16/16\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 1.5661target:     <الحاجه المرعبه وطبعا إحنا كويس إن إنت بتتكلم على >\nprediction: <المراجميله بتبقى في أصارات و في أصغرات و في أصغرا>\n\ntarget:     <أو المؤسسات ونظام المنظومه الدوليه الأمم المتحده >\nprediction: <أول مصر في المصر في المصر في المصر في المصر في ال>\n\ntarget:     <يعني بتمضي على نفسك شرط جزائي ولا لأ>\nprediction: <و زي أنا في مش ميعني بطوجي يعني بطوجيه وزي أنا نف>\n\ntarget:     <إنه ما حدث في تونس ليس بعيدا عن هذه القاعه ثم الم>\nprediction: <المشهد المشهد المشهد المشهد المشهد المشهد المشهد >\n\n\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 216ms/step - loss: 1.5660 - val_loss: 1.6568\n","output_type":"stream"}]}]}